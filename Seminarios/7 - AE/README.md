# CPE727-2025-03/Seminarios/7 - AE
Pasta a ser utilizada para o desenvolvimento do seminário sobre AutoEncoders

## Objetivo do Seminário

O objetivo de um seminário sobre AutoEncoders e o conceito de Aprendizado por Representação em um curso de aprendizado profundo é introduzir aos alunos uma das arquiteturas mais influentes na formação da área moderna de redes neurais, ao mesmo tempo em que se aprofunda no rigor matemático que fundamenta seu funcionamento. Historicamente, os AutoEncoders desempenharam um papel central ao demonstrar que redes neurais poderiam aprender representações compactas e informativas dos dados de forma não supervisionada, em contraste com o foco exclusivo em tarefas de classificação. Esses modelos serviram como base para o avanço de técnicas de redução de dimensionalidade, compressão de dados, detecção de anomalias e até para a construção de arquiteturas mais sofisticadas, como os Variational AutoEncoders (VAEs) e os modelos generativos modernos.

No seminário, será enfatizada a importância de “abrir” todas as equações que regem o treinamento e a inferência dos AutoEncoders, para garantir que os alunos dominem os aspectos matemáticos por trás da intuição. Isso inclui a formulação da transformação de codificação, que mapeia os dados de entrada para um espaço latente de menor dimensão, e da decodificação, que reconstrói a entrada a partir dessa representação. Serão exploradas em detalhe as funções de perda (como o erro quadrático médio ou a entropia cruzada), o processo de retropropagação dos gradientes para atualizar os pesos, bem como a relação entre dimensionalidade do espaço latente e capacidade de generalização. Esse nível de detalhamento permitirá compreender como e por que os AutoEncoders conseguem extrair características relevantes, mesmo sem rótulos explícitos.

O seminário também discutirá o impacto histórico dos AutoEncoders no desenvolvimento do aprendizado por representação, um paradigma que se tornou a base para grande parte das arquiteturas modernas em visão computacional, processamento de linguagem natural e outras áreas. Ao aprender representações latentes, os modelos tornam-se mais eficientes, generalizáveis e capazes de transferir conhecimento entre tarefas distintas, estabelecendo um elo direto com conceitos de pré-treinamento e aprendizado auto-supervisionado.

Assim, o objetivo do seminário é duplo: por um lado, situar os AutoEncoders como marcos históricos que abriram caminho para o aprendizado de representações ricas e reutilizáveis; por outro, consolidar a formação matemática dos alunos ao explorar todas as equações que regem seu funcionamento, tanto no processo de treinamento quanto na fase de inferência. Ao final, os participantes estarão aptos a compreender criticamente os fundamentos desses modelos, aplicá-los em diferentes contextos e perceber sua relevância no ecossistema mais amplo do aprendizado profundo contemporâneo.